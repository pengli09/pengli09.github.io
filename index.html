<!DOCTYPE html>
<html lang="en" itemscope itemtype="https://schema.org/Person">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Peng Li — Research Associate Professor</title>
  <meta name="description" content="Peng Li is a Research Associate Professor at Tsinghua University's Institute for AI Industry Research (AIR). Research interests: LLMs, LLM-based agents, AI4Math." />
  <link rel="icon" href="data:image/svg+xml,<svg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'><text y='0.9em' font-size='90'>🎓</text></svg>"> 
  <style>
    :root{ --bg:#ffffff; --fg:#1b1f24; --muted:#5c6672; --link:#3462DB; --link-visited:#5B2C6F; --card:#f7f9fc; --border:#e5e7eb; --accent:#0ea5e9; }
    @media (prefers-color-scheme: dark){
      :root{ --bg:#0b1020; --fg:#e6e7ea; --muted:#99a2b2; --link:#7aa8ff; --link-visited:#c697ff; --card:#0f152b; --border:#1f2940; --accent:#38bdf8; }
    }
    *{box-sizing:border-box}
    html,body{height:100%}
    body{margin:0; font:16px/1.6 system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica Neue, Arial, "Apple Color Emoji","Segoe UI Emoji"; background:var(--bg); color:var(--fg)}
    a{color:var(--link); text-decoration:none}
    a:hover{text-decoration:underline}
    a:visited{color:var(--link-visited)}
    .container{max-width:1000px; margin:0 auto; padding:28px 20px 60px}
    header{display:grid; grid-template-columns:auto 1fr; gap:20px; align-items:center; margin-top:12px; margin-bottom:20px}
    .avatar{width:120px; height:auto; border-radius:12px; object-fit:contain; background:#fff; box-shadow:0 2px 6px rgba(0,0,0,0.15)}
    .title h1{font-size:32px; line-height:1.2; margin:0}
    .title .role{color:var(--muted); margin-top:6px}
    .badges{display:flex; flex-wrap:wrap; gap:10px; margin-top:14px}
    .badge{display:inline-flex; gap:8px; align-items:center; border:1px solid var(--border); background:var(--card); padding:6px 10px; border-radius:999px; font-size:14px}
    .badge svg{width:16px; height:16px}
    .section{margin-top:34px}
    .section h2{font-size:22px; margin:0 0 12px 0; border-bottom:1px dashed var(--border); padding-bottom:6px}
    .prose{color:var(--fg)}
    .grid{display:grid; gap:14px}
    @media(min-width:820px){.grid-cols-2{grid-template-columns:1fr 1fr}}
    .list{list-style:none; padding:0; margin:0}
    .list .item{padding:8px 0; border-bottom:1px dashed var(--border)}
    .pub-title{font-weight:600}
    .pub-venue{font-style:italic}
    .small{font-size:14px; color:var(--muted)}
    .chips{display:flex; flex-wrap:wrap; gap:8px}
    .chip{background:var(--card); border:1px solid var(--border); padding:2px 8px; border-radius:999px; font-size:12px}
    footer{margin-top:36px; color:var(--muted)}
    .toolbar{display:flex; gap:10px; align-items:center}
    .btn{display:inline-flex; align-items:center; gap:8px; border:1px solid var(--border); background:var(--bg); padding:8px 12px; border-radius:10px}
    .btn:hover{background:var(--card)}
    details.pub{padding:10px 12px; border:1px solid var(--border); border-radius:12px; background:var(--card)}
    details.pub + details.pub{margin-top:10px}
    summary{cursor:pointer; font-weight:600}
    .two-col{columns:1; column-gap:28px}
    @media(min-width:900px){.two-col{columns:2}}
    @media print{a{text-decoration:none} header{grid-template-columns:auto 1fr} .badge,.btn{border:1px solid #ccc}}
  </style>
</head>
<body>
  <div class="container">
    <header>
      <img class="avatar" src="images/pic.jpeg" alt="Peng Li portrait" itemprop="image" />
      <div class="title">
        <h1 itemprop="name">Peng Li</h1>
        <div class="role" itemprop="jobTitle">Research Associate Professor</div>
        <div class="small" itemprop="affiliation" itemscope itemtype="https://schema.org/CollegeOrUniversity">
          <a href="https://air.tsinghua.edu.cn/" itemprop="name">Institute for AI Industry Research (AIR)</a>,
          <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, China
        </div>
        <div class="badges" aria-label="quick links">
          <a class="badge" href="#" id="email-link" title="Email">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor"><path d="M2.25 4.5h19.5v15H2.25z" fill="none" stroke="currentColor"/><path d="M3 6l9 6 9-6"/></svg>
            Email
          </a>
          <a class="badge" href="https://scholar.google.com/citations?user=hgYzkOQAAAAJ&hl=en">Google Scholar</a>
        </div>
      </div>
    </header>

    <section class="section" id="bio">
      <h2>About</h2>
      <p class="prose" itemprop="description">
        Peng Li is a Research Associate Professor at the Institute for AI Industry Research (AIR), Tsinghua University. Before joining Tsinghua, he was a principal researcher and team leader at WeChat AI, Tencent. He also previously worked at Institute of Deep Learning (IDL), Baidu Inc. His research spans Large Language Models (LLMs), LLM-based Agents, AI for mathematics (AI4Math), and Multimodal Large Language Models (MLLMs). He has published over 90 papers in top-tier venues and received the Outstanding Paper Award at ACL 2023. His work ranks first on several influential benchmarks, surpassing teams from Google Research and OpenAI. He has led major scientific research projects, including a key task under the National Science and Technology Innovation - Major Program and the National Natural Science Foundation of China (NSFC) General Program. He has also served as an Area Chair for top-tier international conferences such as ACL, EMNLP, and NAACL. His research has been deployed in Baidu and WeChat, reaching tens of millions of users. He received the First Prize of the Qian Weichang Chinese Information Processing Science and Technology Award by the Chinese Information Processing Society of China (CIPS).
      </p>
      <div class="chips" aria-label="research areas">
        <span class="chip">Large Language Models (LLMs)</span>
        <span class="chip">LLM-based Agents</span>
        <span class="chip">AI4Math</span>
        <span class="chip">Multimodal Large Language Models (MLLMs)</span>
      </div>
      <p class="small" style="margin-top:10px"><strong>Address:</strong> 11/F, Block C, Qidi Science & Technology Building, Tsinghua Science Park, Haidian District, Beijing</p>
    </section>

    <section class="section" id="publications">
      <div class="toolbar" style="justify-content:space-between">
        <h2>Publications & Preprints</h2>
        <a class="btn" href="https://scholar.google.com/citations?user=hgYzkOQAAAAJ&hl=en">View on Google Scholar</a>
      </div>
      <details class="pub" open>
  <summary>2025</summary>
  <div class="two-col">
    <div class="list">
      <div class="item">
  <div class="pub-title">AI Mathematician: Towards Fully Automated Frontier Mathematical Research</div>
  <div class="small">Yuanhang Liu, Yanxing Huang, Yanqiao Wang, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2505.22451">arXiv</a>] [<a href="talks/AIM-en.pdf">Slides</a>] [<a href="talks/AIM-zh.pdf">Slides (in Chinese)</a>]</div>
</div><div class="item">
  <div class="pub-title">ActiView: Evaluating Active Perception Ability for Multimodal Large Language Models</div>
  <div class="small">Ziyue Wang, Chi Chen, Fuwen Luo, Yurui Dong, Yuanchi Zhang, Yuzhuang Xu, Xiaolong Wang, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">ACL 2025</span>, 7605-7633. [<a href="https://aclanthology.org/2025.acl-long.376.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2410.04659">arXiv</a>] [<a href="https://github.com/THUNLP-MT/ActiView">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Perspective Transition of Large Language Models for Solving Subjective Tasks</div>
  <div class="small">Xiaolong Wang, Yuanchi Zhang, Ziyue Wang, Yuzhuang Xu, Fuwen Luo, Yile Wang, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">Findings of ACL 2025</span>, 9686-9704. [<a href="https://aclanthology.org/2025.acl-long.376.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2501.09265">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Scaffolding Coordinates to Promote Vision-Language Coordination in Large Multi-Modal Models</div>
  <div class="small">Xuanyu Lei, Zonghan Yang, Xinrui Chen, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">COLING 2025</span>, 2886-2903. [<a href="https://aclanthology.org/2025.coling-main.195.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2402.12058">arXiv</a>] [<a href="https://github.com/THUNLP-MT/Scaffold">code</a>] [<a href="https://leixy20.github.io/scaffold_site/">Project Webpage</a>]</div>
</div><div class="item">
  <div class="pub-title">Rethinking Long Context Generation from the Continual Learning Perspective</div>
  <div class="small">Zeyuan Yang, Fangzhou Xiong, <strong>Peng Li</strong> and Yang Liu. <span class="pub-venue">COLING 2025</span>, 1922-1933. [<a href="https://aclanthology.org/2025.coling-main.131.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Leveraging Language-based Representations for Better Solving Symbol-related Problems with Large Language Models</div>
  <div class="small">Yile Wang, Sijie Cheng, Zixin Sun, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">COLING 2025</span>, 5544-5557. [<a href="https://aclanthology.org/2025.coling-main.372.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2401.11725">arXiv</a>] [<a href="https://github.com/THUNLP-MT/symbol2language">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Dual-AEB: Synergizing Rule-Based and Multimodal Large Language Models for Effective Emergency Braking</div>
  <div class="small">Wei Zhang, Pengfei Li, Junli Wang, Bingchuan Sun, Qihao Jin, Guangjun Bao, Shibo Rui, Yang Yu, Wenchao Ding, <strong>Peng Li</strong>, Yilun Chen. <span class="pub-venue">ICRA 2025</span>, 14888-14895. [<a href="https://ieeexplore.ieee.org/abstract/document/11128453">pdf</a>] [<a href="https://arxiv.org/abs/2410.08616">arXiv</a>] [<a href="https://github.com/ChipsICU/Dual-AEB">code</a>]</div>
</div><div class="item">
  <div class="pub-title">CoSpace: Benchmarking Continuous Space Perception Ability for Vision-Language Models</div>
  <div class="small">Yiqi Zhu, Ziyue Wang, Can Zhang, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">CVPR 2025</span>, 29569-29579. [<a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Zhu_CoSpace_Benchmarking_Continuous_Space_Perception_Ability_for_Vision-Language_Models_CVPR_2025_paper.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2503.14161">arXiv</a>] [<a href="https://github.com/THUNLP-MT/CoSpace">code</a>] [<a href="https://thunlp-mt.github.io/CoSpace/">Project Webpage</a>]</div>
</div><div class="item">
  <div class="pub-title">AdaMMS: Model Merging for Heterogeneous Multimodal Large Language Models with Unsupervised Coefficient Optimization</div>
  <div class="small">Yiyang Du, Xiaochen Wang, Chi Chen, Jiabo Ye, Yiru Wang, <strong>Peng Li</strong>, Ming Yan, Ji Zhang, Fei Huang, Zhifang Sui, Maosong Sun, Yang Liu. <span class="pub-venue">CVPR 2025</span>, 9413-9422. [<a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Du_AdaMMS_Model_Merging_for_Heterogeneous_Multimodal_Large_Language_Models_with_CVPR_2025_paper.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2503.23733">arXiv</a>] [<a href="https://github.com/THUNLP-MT/AdaMMS">code</a>] [<a href="talks/AdaMMS-en.pdf">Slides</a>]</div>
</div><div class="item">
  <div class="pub-title">How Do Multimodal Large Language Models Handle Complex Multimodal Reasoning? Placing Them in An Extensible Escape Game</div>
  <div class="small">Ziyue Wang, Yurui Dong, Fuwen Luo, Minyuan Ruan, Zhili Cheng, Chi Chen, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">ICCV 2025</span>. [<a href="https://arxiv.org/abs/2503.10042">arXiv</a>] [<a href="https://github.com/THUNLP-MT/EscapeCraft">code</a>] [<a href="talks/MM-Escape-en.pdf">Slides</a>] [<a href="videos/MM-Escape.mp4">Video</a>] [<a href="https://x.com/Tsinghua_Uni/status/1960372139967516889">Media 1</a>] [<a href="https://www.facebook.com/Tsinghua/posts/pfbid0tEaC28Bu7ZtK1YijcbKx8YBFqS8TWtUDMLDkUnRpVjQ4ZuZV8x1s1NQ79yFkY8j9l?rdid=NlLe9tMS5wmyBLYR#">Media 2</a>]</div>
</div><div class="item">
  <div class="pub-title">LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents</div>
  <div class="small">Boyu Chen, Zhengrong Yue, Siran Chen, Zikang Wang, Yang Liu, <strong>Peng Li</strong>, Yali Wang. <span class="pub-venue">ICCV 2025</span>. [<a href="https://arxiv.org/abs/2503.10200">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Adversarial Robust Memory-Based Continual Learner</div>
  <div class="small">Xiaoyue Mi, Fan Tang, Zonghan Yang, Danding Wang, Juan Cao, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">ICCV 2025</span>. [<a href="https://arxiv.org/abs/2311.17608">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Contrastive Private Data Synthesis via Weighted Multi-PLM Fusion</div>
  <div class="small">Tianyuan Zou, Yang Liu, <strong>Peng Li</strong>, Yufei Xiong, Jianqing Zhang, Jingjing Liu, Xiaozhou Ye, Ye Ouyang, Ya-Qin Zhang. <span class="pub-venue">ICML 2025</span>. [<a href="https://arxiv.org/abs/2502.00245">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Bench4Merge: A Comprehensive Benchmark for Merging in Realistic Dense Traffic with Micro-Interactive Vehicles</div>
  <div class="small">Zhengming Wang, Junli Wang, Pengfei Li, Zhaohan Li, Chunyang Liu, Bo Zhang, <strong>Peng Li</strong>, Yilun Chen. <span class="pub-venue">IROS 2025</span>. [<a href="https://arxiv.org/abs/2410.15912">arXiv</a>] [<a href="https://github.com/WZM5853/Bench4Merge">code</a>] [<a href="videos/Bench4Merge.mp4">Video</a>]</div>
</div><div class="item">
  <div class="pub-title">EditEval: Towards Comprehensive and Automatic Evaluation for Text-guided Video Editing</div>
  <div class="small">Bingshuai Liu, Ante Wang, Zijun Min, Chenyang Lyu, Longyue Wang, Zhihao Wang, Xu Han, <strong>Peng Li</strong>, Jinsong Su. <span class="pub-venue">ACMMM 2025</span>. </div>
</div><div class="item">
  <div class="pub-title">Advancing Language Multi-Agent Learning with Credit Re-Assignment for Interactive Environment Generalization</div>
  <div class="small">Zhitao He, Zijun Liu, <strong>Peng Li</strong>, Yi R Fung, Ming Yan, Ji Zhang, Fei Huang, Yang Liu. <span class="pub-venue">COLM 2025</span>. [<a href="https://openreview.net/pdf?id=SoEmgM1ioC">pdf</a>] [<a href="https://arxiv.org/abs/2502.14496">arXiv</a>] [<a href="https://github.com/THUNLP-MT/CollabUIAgents">code</a>] [<a href="talks/CollabUlAgents-zh.pdf">Slides (in Chinese)</a>]</div>
</div><div class="item">
  <div class="pub-title">FormaRL: Enhancing Autoformalization with no Labeled Data</div>
  <div class="small">Yanxing Huang, Xinling Jin, Sijie Liang, Fuwen Luo, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">COLM 2025</span>. [<a href="https://openreview.net/pdf?id=Z2El1U94bq">pdf</a>] [<a href="https://arxiv.org/abs/2508.18914">arXiv</a>] [<a href="https://github.com/THUNLP-MT/FormaRL">code</a>]</div>
</div><div class="item">
  <div class="pub-title">MUCAR: Benchmarking Multilingual Cross-Modal Ambiguity Resolution for Multimodal Large Language Models</div>
  <div class="small">Xiaolong Wang, Zhaolu Kang, Wangyuxuan Zhai, Xinyue Lou, Yunghwei Lai, Ziyue Wang, Yawen Wang, Kaiyu Huang, Yile Wang, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">EMNLP 2025</span>. [<a href="https://arxiv.org/abs/2506.17046">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">G2: Guided Generation for Enhanced Output Diversity in LLMs</div>
  <div class="small">Zhiwen Ruan, Yixia Li, Yefeng Liu, Yun Chen, Weihua Luo, <strong>Peng Li</strong>, Yang Liu, Guanhua Chen. <span class="pub-venue">EMNLP 2025</span>. </div>
</div><div class="item">
  <div class="pub-title">DongbaMIE: A Multimodal Information Extraction Dataset for Evaluating Semantic Understanding of Dongba Pictograms</div>
  <div class="small">Xiaojun Bi, Shuo Li, Junyao Xing, Ziyue Wang, Fuwen Luo, Weizheng Qiao, Lu Han, Ziwei Sun, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">Findings of EMNLP 2025</span>. [<a href="https://arxiv.org/abs/2503.03644">arXiv</a>] [<a href="https://github.com/thinklis/DongbaMIE">code</a>] [<a href="https://huggingface.co/datasets/thinklis/DongbaMIE">Dataset</a>]</div>
</div><div class="item">
  <div class="pub-title">PATIMT-Bench: A Multi-Scenario Benchmark for Position-Aware Text Image Machine Translation in Large Vision-Language Models</div>
  <div class="small">Wanru Zhuang, Wenbo Li, Zhibin Lan, Xu Han, <strong>Peng Li</strong>, Jinsong Su. <span class="pub-venue">Findings of EMNLP 2025</span>. </div>
</div><div class="item">
  <div class="pub-title">Beyond the Surface: Enhancing LLM-as-a-Judge Alignment with Human via Internal Representations</div>
  <div class="small">Peng Lai, Jianjie Zheng, Sijie Cheng, Yun Chen, <strong>Peng Li</strong>, Yang Liu, Guanhua Chen. <span class="pub-venue">NeurIPS 2025</span>. </div>
</div><div class="item">
  <div class="pub-title">Agent-Environment Alignment via Automated Interface Generation</div>
  <div class="small">Kaiming Liu, Xuanyu Lei, Ziyue Wang, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2505.21055">arXiv</a>] [<a href="talks/ALIGN-en.pdf">Slides</a>]</div>
</div><div class="item">
  <div class="pub-title">MUSEG: Reinforcing Video Temporal Understanding via Timestamp-Aware Multi-Segment Grounding</div>
  <div class="small">Fuwen Luo, Shengfeng Lou, Chi Chen, Ziyue Wang, Chenliang Li, Weizhou Shen, Jiyue Guo, <strong>Peng Li</strong>, Ming Yan, Ji Zhang, Fei Huang, Yang Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2505.20715">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Inference-Time Scaling for Generalist Reward Modeling</div>
  <div class="small">Zijun Liu, Peiyi Wang, Runxin Xu, Shirong Ma, Chong Ruan, <strong>Peng Li</strong>, Yang Liu, Yu Wu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2504.02495">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">LiloDriver: A Lifelong Learning Framework for Closed-loop Motion Planning in Long-tail Autonomous Driving Scenarios</div>
  <div class="small">Huaiyuan Yao, Pengfei Li, Bu Jin, Yupeng Zheng, An Liu, Lisen Mu, Qing Su, Qian Zhang, Yilun Chen, <strong>Peng Li</strong>. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2505.17209">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Visual Abstract Thinking Empowers Multimodal Reasoning</div>
  <div class="small">Dairu Liu, Ziyue Wang, Minyuan Ruan, Fuwen Luo, Chi Chen, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2505.20164">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">A Survey of Efficient Reasoning for Large Reasoning Models: Language, Multimodality, and Beyond</div>
  <div class="small">Xiaoye Qu, Yafu Li, Zhaochen Su, Weigao Sun, Jianhao Yan, Dongrui Liu, Ganqu Cui, Daizong Liu, Shuxian Liang, Junxian He, <strong>Peng Li</strong>, Wei Wei, Jing Shao, Chaochao Lu, Yue Zhang, Xian-Sheng Hua, Bowen Zhou, Yu Cheng. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2503.21614">arXiv</a>] [<a href="https://github.com/XiaoYee/Awesome_Efficient_LRM_Reasoning">Project Webpage</a>]</div>
</div><div class="item">
  <div class="pub-title">Scaling External Knowledge Input Beyond Context Windows of LLMs via Multi-Agent Collaboration</div>
  <div class="small">Zijun Liu, Zhennan Wan, <strong>Peng Li</strong>, Ming Yan, Ji Zhang, Fei Huang, Yang Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2505.21471">arXiv</a>] [<a href="https://github.com/THUNLP-MT/ExtAgents">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Writing-RL: Advancing Long-form Writing via Adaptive Curriculum Reinforcement Learning</div>
  <div class="small">Xuanyu Lei, Chenliang Li, Yuning Wu, Kaiming Liu, Weizhou Shen, <strong>Peng Li</strong>, Ming Yan, Ji Zhang, Fei Huang, Yang Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2506.05760">arXiv</a>] [<a href="https://github.com/Tongyi-Zhiwen/Writing-RL">code</a>]</div>
</div>
    </div>
  </div>
</details>
<details class="pub" >
  <summary>2024</summary>
  <div class="two-col">
    <div class="list">
      <div class="item">
  <div class="pub-title">Position: Towards Unified Alignment Between Agents, Humans, and Environment</div>
  <div class="small">Zonghan Yang, An Liu, Zijun Liu, Kaiming Liu, Fangzhou Xiong, Yile Wang, Zeyuan Yang, Qingyuan Hu, Xinrui Chen, Zhenhe Zhang, Fuwen Luo, Zhicheng Guo, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">ICML 2024</span>, 56251-56275. [<a href="https://proceedings.mlr.press/v235/yang24p.html">pdf</a>] [<a href="https://arxiv.org/abs/2402.07744">arXiv</a>] [<a href="https://agent-force.github.io/unified-alignment-for-agents.html">Project Webpage</a>]</div>
</div><div class="item">
  <div class="pub-title">CODIS: Benchmarking Context-Dependent Visual Comprehension for Multimodal Large Language Models</div>
  <div class="small">Fuwen Luo, Chi Chen, Zihao Wan, Zhaolu Kang, Qidong Yan, Yingjie Li, Xiaolong Wang, Siyu Wang, Ziyue Wang, Xiaoyue Mi, <strong>Peng Li</strong>, Ning Ma, Maosong Sun, Yang Liu. <span class="pub-venue">ACL 2024</span>, 10639-10659. [<a href="https://aclanthology.org/2024.acl-long.573.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2402.13607">arXiv</a>] [<a href="https://github.com/THUNLP-MT/CODIS">code</a>] [<a href="https://thunlp-mt.github.io/CODIS">Project Webpage</a>]</div>
</div><div class="item">
  <div class="pub-title">Browse and Concentrate: Comprehending Multimodal Content via prior-LLM Context Fusion</div>
  <div class="small">Ziyue Wang, Chi Chen, Yiqi Zhu, Fuwen Luo, <strong>Peng Li</strong>, Ming Yan, Ji Zhang, Fei Huang, Maosong Sun, Yang Liu. <span class="pub-venue">ACL 2024</span>, 11229-11245. [<a href="https://aclanthology.org/2024.acl-long.605.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2402.12195">arXiv</a>] [<a href="https://github.com/THUNLP-MT/Brote">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Model Composition for Multimodal Large Language Models</div>
  <div class="small">Chi Chen, Yiyang Du, Zheng Fang, Ziyue Wang, Fuwen Luo, <strong>Peng Li</strong>, Ming Yan, Ji Zhang, Fei Huang, Maosong Sun, Yang Liu. <span class="pub-venue">ACL 2024</span>, 11246-11262. [<a href="https://aclanthology.org/2024.acl-long.606.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2402.12750">arXiv</a>] [<a href="https://github.com/THUNLP-MT/ModelCompose">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Enhancing Multilingual Capabilities of Large Language Models through Self-Distillation from Resource-Rich Languages</div>
  <div class="small">Yuanchi Zhang, Yile Wang, Zijun Liu, Shuo Wang, Xiaolong Wang, <strong>Peng Li</strong>, Maosong Sun, Yang Liu. <span class="pub-venue">ACL 2024</span>, 11189-11204. [<a href="https://aclanthology.org/2024.acl-long.603.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2402.12204">arXiv</a>] [<a href="https://github.com/THUNLP-MT/SDRRL">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Reasoning in Conversation: Solving Subjective Tasks through Dialogue Simulation for Large Language Models</div>
  <div class="small">Xiaolong Wang, Yile Wang, Yuanchi Zhang, Fuwen Luo, <strong>Peng Li</strong>, Maosong Sun, Yang Liu. <span class="pub-venue">ACL 2024</span>, 15880-15893. [<a href="https://aclanthology.org/2024.acl-long.844.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2402.17226">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">StableToolBench: Towards Stable Large-Scale Benchmarking on Tool Learning of Large Language Models</div>
  <div class="small">Zhicheng Guo, Sijie Cheng, Hao Wang, Shihao Liang, Yujia Qin, <strong>Peng Li</strong>, Zhiyuan Liu, Maosong Sun, Yang Liu. <span class="pub-venue">Findings of ACL 2024</span>, 11143-11156. [<a href="https://aclanthology.org/2024.findings-acl.664.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2403.07714">arXiv</a>] [<a href="https://github.com/THUNLP-MT/StableToolBench">code</a>] [<a href="https://zhichengg.github.io/stb.github.io/">Project Webpage</a>]</div>
</div><div class="item">
  <div class="pub-title">PANDA: Preference Adaptation for Enhancing Domain-Specific Abilities of LLMs</div>
  <div class="small">An Liu, Zonghan Yang, Zhenhe Zhang, Qingyuan Hu, <strong>Peng Li</strong>, Ming Yan, Ji Zhang, Fei Huang, Yang Liu. <span class="pub-venue">Findings of ACL 2024</span>, 10960-10977. [<a href="https://aclanthology.org/2024.findings-acl.651.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2402.12835">arXiv</a>] [<a href="https://github.com/THUNLP-MT/PANDA">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Budget-Constrained Tool Learning with Planning</div>
  <div class="small">Yuanhang Zheng, <strong>Peng Li</strong>, Ming Yan, Ji Zhang, Fei Huang, Yang Liu. <span class="pub-venue">Findings of ACL 2024</span>, 9039-9052. [<a href="https://aclanthology.org/2024.findings-acl.536.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2402.15960">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">ReAct Meets ActRe: Autonomous Annotation of Agent Trajectories for Contrastive Self-Training</div>
  <div class="small">Zonghan Yang, <strong>Peng Li</strong>, Ming Yan, Ji Zhang, Fei Huang, Yang Liu. <span class="pub-venue">COLM 2024</span>. [<a href="https://openreview.net/pdf?id=0VLBwQGWpA">pdf</a>] [<a href="https://arxiv.org/abs/2403.14589">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">A Dynamic LLM-Powered Agent Network for Task-Oriented Agent Collaboration</div>
  <div class="small">Zijun Liu, Yanzhe Zhang, <strong>Peng Li</strong>, Yang Liu, Diyi Yang. <span class="pub-venue">COLM 2024</span>. [<a href="https://openreview.net/pdf?id=XII0Wp1XA9">pdf</a>] [<a href="https://arxiv.org/abs/2310.02170">arXiv</a>] [<a href="https://github.com/SALT-NLP/DyLAN">code</a>]</div>
</div><div class="item">
  <div class="pub-title">ToolRerank: Adaptive and Hierarchy-Aware Reranking for Tool Retrieval</div>
  <div class="small">Yuanhang Zheng, <strong>Peng Li</strong>, Wei Liu, Yang Liu, Jian Luan, Bin Wang. <span class="pub-venue">COLING 2024</span>, 16263-16273. [<a href="https://aclanthology.org/2024.lrec-main.1413.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2403.06551">arXiv</a>] [<a href="https://github.com/XiaoMi/ToolRerank">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Pluggable Neural Machine Translation Models via Memory-augmented Adapters</div>
  <div class="small">Yuzhuang Xu, Shuo Wang, <strong>Peng Li</strong>, Xuebo Liu, Xiaolong Wang, Weidong Liu, Yang Liu. <span class="pub-venue">COLING 2024</span>, 12794-12808. [<a href="https://aclanthology.org/2024.lrec-main.1120.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2307.06029">arXiv</a>] [<a href="https://github.com/xuyuzhuang11/StyleMT">code</a>]</div>
</div><div class="item">
  <div class="pub-title">DEEM: Dynamic Experienced Expert Modeling for Stance Detection</div>
  <div class="small">Xiaolong Wang, Yile Wang, Sijie Cheng, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">COLING 2024</span>, 4530-4541. [<a href="https://aclanthology.org/2024.lrec-main.405.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2402.15264">arXiv</a>] [<a href="https://github.com/THUNLP-MT/DEEM">code</a>]</div>
</div><div class="item">
  <div class="pub-title">EgoThink: Evaluating First-Person Perspective Thinking Capability of Vision-Language Models</div>
  <div class="small">Sijie Cheng, Zhicheng Guo, Jingwen Wu, Kechen Fang, <strong>Peng Li</strong>, Huaping Liu, Yang Liu. <span class="pub-venue">CVPR 2024</span>, 14291-14302. [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Cheng_EgoThink_Evaluating_First-Person_Perspective_Thinking_Capability_of_Vision-Language_Models_CVPR_2024_paper.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2311.15596">arXiv</a>] [<a href="https://github.com/AdaCheng/EgoThink">code</a>] [<a href="https://adacheng.github.io/EgoThink/">Project Webpage</a>]</div>
</div><div class="item">
  <div class="pub-title">FuseGen: PLM Fusion for Data-generation based Zero-shot Learning</div>
  <div class="small">Tianyuan Zou, Yang Liu, <strong>Peng Li</strong>, Jianqing Zhang, Jingjing Liu, Ya-Qin Zhang. <span class="pub-venue">EMNLP 2024</span>, 2172-2190. [<a href="https://aclanthology.org/2024.emnlp-main.130.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2406.12527">arXiv</a>] [<a href="https://github.com/LindaLydia/FuseGen">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Black-box Prompt Tuning with Subspace Learning</div>
  <div class="small">Yuanhang Zheng, Zhixing Tan, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)</span>, (32):3002-3013. [<a href="https://ieeexplore.ieee.org/document/10551912?source=authoralert">pdf</a>] [<a href="https://arxiv.org/abs/2305.03518">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Exploring Universal Intrinsic Task Subspace for Few-shot Learning via Prompt Tuning</div>
  <div class="small">Yujia Qin, Xiaozhi Wang, Yusheng Su, Yankai Lin, Ning Ding, Jing Yi, Weize Chen, Zhiyuan Liu, Juanzi Li, Lei Hou, <strong>Peng Li</strong>, Maosong Sun, Jie Zhou. <span class="pub-venue">IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)</span>, (32):3631-3643. [<a href="https://ieeexplore.ieee.org/document/10603438">pdf</a>] [<a href="https://arxiv.org/abs/2110.07867">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Topology-preserving Adversarial Training for Alleviating Natural Accuracy Degradation</div>
  <div class="small">Xiaoyue Mi, Fan Tang, Yepeng Weng, Danding Wang, Juan Cao, Sheng Tang, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">BMVC 2024</span>. [<a href="https://bmvc2024.org/proceedings/168/">pdf</a>] [<a href="https://arxiv.org/abs/2311.17607">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">AIGS: Generating Science from AI-Powered Automated Falsification</div>
  <div class="small">Zijun Liu, Kaiming Liu, Yiqi Zhu, Xuanyu Lei, Zonghan Yang, Zhenhe Zhang, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2411.11910">arXiv</a>] [<a href="https://agent-force.github.io/AIGS/">Project Webpage</a>] [<a href="talks/AIGS-zh.pdf">Slides (in Chinese)</a>]</div>
</div><div class="item">
  <div class="pub-title">Personal LLM Agents: Insights and Survey about the Capability, Efficiency and Security</div>
  <div class="small">Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong Liu, Jiacheng Liu, Wenxing Xu, Xiang Wang, Yi Sun, Rui Kong, Yile Wang, Hanfei Geng, Jian Luan, Xuefeng Jin, Zilong Ye, Guanjing Xiong, Fan Zhang, Xiang Li, Mengwei Xu, Zhijun Li, <strong>Peng Li</strong>, Yang Liu, Ya-Qin Zhang, Yunxin Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2401.05459">arXiv</a>] [<a href="https://github.com/MobileLLM/Personal_LLM_Agents_Survey">Paper List</a>]</div>
</div><div class="item">
  <div class="pub-title">Enabling Weak LLMs to Judge Response Reliability via Meta Ranking</div>
  <div class="small">Zijun Liu, Boqun Kou, <strong>Peng Li</strong>, Ming Yan, Ji Zhang, Fei Huang, Yang Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2402.12146">arXiv</a>] [<a href="https://github.com/THUNLP-MT/MetaRanking">code</a>]</div>
</div><div class="item">
  <div class="pub-title">StreamingBench: Assessing the Gap for MLLMs to Achieve Streaming Video Understanding</div>
  <div class="small">Junming Lin, Zheng Fang, Chi Chen, Zihao Wan, Fuwen Luo, <strong>Peng Li</strong>, Yang Liu, Maosong Sun. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2411.03628">arXiv</a>] [<a href="https://github.com/THUNLP-MT/StreamingBench">code</a>] [<a href="https://streamingbench.github.io/">Project Webpage</a>]</div>
</div><div class="item">
  <div class="pub-title">Visual-Friendly Concept Protection via Selective Adversarial Perturbations</div>
  <div class="small">Xiaoyue Mi, Fan Tang, Juan Cao, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2408.08518">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Agent Hospital: A Simulacrum of Hospital with Evolvable Medical Agents</div>
  <div class="small">Junkai Li, Yunghwei Lai, Weitao Li, Jingyi Ren, Meng Zhang, Xinhui Kang, Siyu Wang, <strong>Peng Li</strong>, Ya-Qin Zhang, Weizhi Ma, Yang Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2405.02957">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Interactive Visual Assessment for Text-to-Image Generation Models</div>
  <div class="small">Xiaoyue Mi, Fan Tang, Juan Cao, Qiang Sheng, Ziyao Huang, <strong>Peng Li</strong>, Yang Liu, Tong-Yee Lee. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2411.15509">arXiv</a>]</div>
</div>
    </div>
  </div>
</details>
<details class="pub" >
  <summary>2023</summary>
  <div class="two-col">
    <div class="list">
      <div class="item">
  <div class="pub-title">Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation</div>
  <div class="small">Zeyuan Yang, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">EMNLP 2023</span>, 1751-1777. [<a href="https://aclanthology.org/2023.emnlp-main.109.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2310.15746">arXiv</a>] [<a href="https://github.com/THUNLP-MT/TRAN">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Learn and Consolidate: Continual Adaptation for Zero-Shot and Multilingual Neural Machine Translation</div>
  <div class="small">Kaiyu Huang, <strong>Peng Li</strong>, Junpeng Liu, Maosong Sun, Yang Liu. <span class="pub-venue">EMNLP 2023</span>, 13938-13951. [<a href="https://aclanthology.org/2023.emnlp-main.860.pdf">pdf</a>] [<a href="https://github.com/koukaiu/LCCA">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Revisiting Source Context in Nearest Neighbor Machine Translation</div>
  <div class="small">Xuanhong Li, <strong>Peng Li</strong>, Po Hu. <span class="pub-venue">EMNLP 2023</span>, 8087-8098. [<a href="https://aclanthology.org/2023.emnlp-main.503.pdf">pdf</a>] [<a href="https://github.com/li-xuanhong/source-context-knn-mt">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Self-Knowledge Guided Retrieval Augmentation for Large Language Models</div>
  <div class="small">Yile Wang, <strong>Peng Li</strong>, Maosong Sun, Yang Liu. <span class="pub-venue">Findings of EMNLP 2023</span>, 10303-10315. [<a href="https://aclanthology.org/2023.findings-emnlp.691.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2310.05002">arXiv</a>] [<a href="https://github.com/THUNLP-MT/SKR">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Filling the Image Information Gap for VQA: Prompting Large Language Models to Proactively Ask Questions</div>
  <div class="small">Ziyue Wang, Chi Chen, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">Findings of EMNLP 2023</span>, 2874-2890. [<a href="https://aclanthology.org/2023.findings-emnlp.189.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2311.11598">arXiv</a>] [<a href="https://github.com/THUNLP-MT/FIIG">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf</div>
  <div class="small">Yuzhuang Xu, Shuo Wang, <strong>Peng Li</strong>, Fuwen Luo, Xiaolong Wang, Weidong Liu and Yang Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2309.04658">arXiv</a>] [<a href="https://github.com/xuyuzhuang11/Werewolf">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Position-Enhanced Visual Instruction Tuning for Multimodal Large Language Models</div>
  <div class="small">Chi Chen, Ruoyu Qin, Fuwen Luo, Xiaoyue Mi, <strong>Peng Li</strong>, Maosong Sun, Yang Liu. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2308.13437">arXiv</a>] [<a href="https://github.com/PVIT-official/PVIT">code</a>] [<a href="https://huggingface.co/spaces/PVIT/pvit">Demo</a>]</div>
</div><div class="item">
  <div class="pub-title">Knowledge Transfer in Incremental Learning for Multilingual Neural Machine Translation</div>
  <div class="small">Kaiyu Huang, <strong>Peng Li</strong>, Jin Ma, Ting Yao, Yang Liu. <span class="pub-venue">ACL 2023</span>, 15286-15304. [<a href="https://aclanthology.org/2023.acl-long.852.pdf">pdf</a>] [<a href="https://github.com/THUNLP-MT/ktnmt">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Bridging the Gap between Decision and Logits in Decision-based Knowledge Distillation for Pre-trained Language Models</div>
  <div class="small">Qinhong Zhou, Zonghan Yang, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">ACL 2023</span>, 13234-13248. [<a href="https://aclanthology.org/2023.acl-long.738.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2306.08909">arXiv</a>] [<a href="https://github.com/THUNLP-MT/DBKD-PLM">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Weakly Supervised Vision-and-Language Pre-training with Relative Representations</div>
  <div class="small">Chi Chen, <strong>Peng Li</strong>, Maosong Sun, Yang Liu. <span class="pub-venue">ACL 2023</span>, 8341-8355. [<a href="https://aclanthology.org/2023.acl-long.464.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2305.15483">arXiv</a>] [<a href="https://github.com/THUNLP-MT/RELIT">code</a>]</div>
</div><div class="item">
  <div class="pub-title">An Extensible Plug-and-Play Method for Multi-Aspect Controllable Text Generation</div>
  <div class="small">Xuancheng Huang, Zijun Liu, <strong>Peng Li</strong>, Tao Li, Maosong Sun, Yang Liu. <span class="pub-venue">ACL 2023</span>, 15233-15256. [<a href="https://aclanthology.org/2023.acl-long.849.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2212.09387">arXiv</a>] [<a href="https://github.com/THUNLP-MT/PromptGating4MCTG">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Continual Knowledge Distillation for Neural Machine Translation</div>
  <div class="small">Yuanchi Zhang, <strong>Peng Li</strong>, Maosong Sun, Yang Liu. <span class="pub-venue">ACL 2023</span>, 7978-7996. [<a href="https://aclanthology.org/2023.acl-long.443.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2212.09097">arXiv</a>] [<a href="https://github.com/THUNLP-MT/CKD">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Hard Sample Aware Prompt-Tuning</div>
  <div class="small">Yuanjian Xu, Qi An, Jiahuan Zhang, <strong>Peng Li</strong>, Zaiqing Nie. <span class="pub-venue">ACL 2023</span>, 12356-12369. [<a href="https://aclanthology.org/2023.acl-long.690.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Plug-and-Play Knowledge Injection for Pre-trained Language Models</div>
  <div class="small">Zhengyan Zhang, Zhiyuan Zeng, Yankai Lin, Huadong Wang, Deming Ye, Chaojun Xiao, Xu Han, Zhiyuan Liu, <strong>Peng Li</strong>, Maosong Sun, Jie Zhou. <span class="pub-venue">ACL 2023</span>, 10641-10658. [<a href="https://aclanthology.org/2023.acl-long.594.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2305.17691">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Prompt-Guided Retrieval Augmentation for Non-Knowledge-Intensive Tasks</div>
  <div class="small">Zhicheng Guo, Sijie Cheng, Yile Wang, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">Findings of ACL 2023</span>, 10896-10912. [<a href="https://aclanthology.org/2023.findings-acl.693.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2305.17653">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Improving Adversarial Robustness of Deep Equilibrium Models with Explicit Regulations Along the Neural Dynamics</div>
  <div class="small">Zonghan Yang, <strong>Peng Li</strong>, Tianyu Pang, Yang Liu. <span class="pub-venue">ICML 2023</span>, 39349-39364. [<a href="https://proceedings.mlr.press/v202/yang23i/yang23i.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2306.01435">arXiv</a>] [<a href="https://github.com/minicheshire/DEQ-Regulating-Neural-Dynamics">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Unified Detoxifying and Debiasing in Language Generation via Inference-time Adaptive Optimization</div>
  <div class="small">Zonghan Yang, Xiaoyuan Yi, <strong>Peng Li</strong>, Yang Liu, Xing Xie. <span class="pub-venue">ICLR 2023</span>. [<a href="https://openreview.net/pdf?id=FvevdI0aA_h">pdf</a>] [<a href="https://arxiv.org/abs/2210.04492">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Learning to Relate to Previous Turns in Conversational Search</div>
  <div class="small">Fengran Mo, Jian-Yun Nie, Kaiyu Huang, Kelong Mao, Yutao Zhu, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">KDD 2023</span>, 1722-1732. [<a href="https://dl.acm.org/doi/pdf/10.1145/3580305.3599411">pdf</a>] [<a href="https://arxiv.org/abs/2306.02553">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Exploring the Effectiveness of Student Behavior in Prerequisite Relation Discovery for Concepts</div>
  <div class="small">Jifan Yu, Hanming Li, Gan Luo, Yankai Lin, <strong>Peng Li</strong>, Jianjun Xu, Lei Hou, Bin Xu. <span class="pub-venue">APWeb-WAIM 2023</span>, 359-374. [<a href="https://link.springer.com/chapter/10.1007/978-981-97-2421-5_24">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">When to Trust Aggregated Gradients: Addressing Negative Client Sampling in Federated Learning</div>
  <div class="small">Wenkai Yang, Yankai Lin, Guangxiang Zhao, <strong>Peng Li</strong>, Jie Zhou, Xu Sun. <span class="pub-venue">Transactions on Machine Learning Research (TMLR)</span>, 2835-8856. [<a href="https://openreview.net/pdf?id=v73h3bYE2Z">pdf</a>] [<a href="https://arxiv.org/abs/2301.10400">arXiv</a>] [<a href="https://github.com/keven980716/Federated_Learning_Experiments">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Gradual Syntactic Label Replacement for Language Model Pre-training</div>
  <div class="small">Yile Wang, Yue Zhang, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)</span>, (32):486-496. [<a href="https://ieeexplore.ieee.org/document/10315017">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">AdaDS: Adaptive Data Selection for Accelerating Pre-trained Language Model Knowledge Distillation</div>
  <div class="small">Qinhong Zhou, <strong>Peng Li</strong>, Yang Liu, Yuyang Guan, Qizhou Xing, Ming Chen, Maosong Sun, Yang Liu. <span class="pub-venue">AI Open</span>, (4):56-63. [<a href="https://www.sciencedirect.com/science/article/pii/S2666651023000074">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Restricted Orthogonal Gradient Projection for Continual Learning</div>
  <div class="small">Zeyuan Yang, Zonghan Yang, Yichen Liu, <strong>Peng Li</strong>, Yang Liu. <span class="pub-venue">AI Open</span>, (4):98-110. [<a href="https://www.sciencedirect.com/science/article/pii/S2666651023000128">pdf</a>] [<a href="https://arxiv.org/abs/2301.12131">arXiv</a>]</div>
</div>
    </div>
  </div>
</details>
<details class="pub" >
  <summary>2022</summary>
  <div class="two-col">
    <div class="list">
      <div class="item">
  <div class="pub-title">End-to-End Unsupervised Vision-and-Language Pre-training with Referring Expression Matching</div>
  <div class="small">Chi Chen, <strong>Peng Li</strong>, Maosong Sun, Yang Liu. <span class="pub-venue">EMNLP 2022</span>, 10799-10810. [<a href="https://aclanthology.org/2022.emnlp-main.742.pdf">pdf</a>] [<a href="https://github.com/THUNLP-MT/E2E-UVLP">code</a>]</div>
</div><div class="item">
  <div class="pub-title">A Template-based Method for Constrained Neural Machine Translation</div>
  <div class="small">Shuo Wang, <strong>Peng Li</strong>, Zhixing Tan, Zhaopeng Tu, Maosong Sun, Yang Liu. <span class="pub-venue">EMNLP 2022</span>, 3665-3679. [<a href="https://aclanthology.org/2022.emnlp-main.240.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2205.11255">arXiv</a>] [<a href="https://github.com/THUNLP-MT/Template-NMT">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Entropy-Based Vocabulary Substitution for Incremental Learning in Multilingual Neural Machine Translation</div>
  <div class="small">Kaiyu Huang, <strong>Peng Li</strong>, Jin Ma, Yang Liu. <span class="pub-venue">EMNLP 2022</span>, 10537-10550. [<a href="https://aclanthology.org/2022.emnlp-main.720.pdf">pdf</a>] [<a href="https://github.com/koukaiu/evs">code</a>]</div>
</div><div class="item">
  <div class="pub-title">ROSE: Robust Selective Fine-tuning for Pre-trained Language Models</div>
  <div class="small">Lan Jiang, Hao Zhou, Yankai Lin, <strong>Peng Li</strong>, Jie Zhou, Rui Jiang. <span class="pub-venue">EMNLP 2022</span>, 2886-2897. [<a href="https://aclanthology.org/2022.emnlp-main.186.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2210.09658">arXiv</a>] [<a href="https://github.com/jiangllan/ROSE">code</a>]</div>
</div><div class="item">
  <div class="pub-title">MAVEN-ERE: A Unified Large-scale Dataset for Event Coreference, Temporal, Causal and Subevent Relation Extraction</div>
  <div class="small">Xiaozhi Wang, Yulin Chen, Ning Ding, Hao Peng, Zimu Wang, Yankai Lin, Xu Han, Lei Hou, Juanzi Li, Zhiyuan Liu, <strong>Peng Li</strong>, Jie Zhou. <span class="pub-venue">EMNLP 2022</span>, 926-941. [<a href="https://aclanthology.org/2022.emnlp-main.60.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2211.07342">arXiv</a>] [<a href="https://github.com/THU-KEG/MAVEN-ERE">code</a>]</div>
</div><div class="item">
  <div class="pub-title">From Mimicking to Integrating: Knowledge Integration for Pre-Trained Language Models</div>
  <div class="small">Lei Li, Yankai Lin, Xuancheng Ren, Guangxiang Zhao, <strong>Peng Li</strong>, Jie Zhou, Xu Sun. <span class="pub-venue">Findings of EMNLP 2022</span>, 6420-6431. [<a href="https://aclanthology.org/2022.findings-emnlp.477.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2112.07327">arXiv</a>] [<a href="https://github.com/lancopku/MUKI">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Event Detection with Dual Relational Graph Attention Networks</div>
  <div class="small">Jiaxin Mi, Po Hu, <strong>Peng Li</strong>. <span class="pub-venue">COLING 2022</span>, 1979-1989. [<a href="https://aclanthology.org/2022.coling-1.172.pdf">pdf</a>] [<a href="https://github.com/Macvh/DualGAT">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Rethinking the Promotion Brought by Contrastive Learning to Semi-Supervised Node Classification</div>
  <div class="small">Deli Chen, Yankai Lin, Lei Li, Xuancheng Ren, <strong>Peng Li</strong>, Jie Zhou, Xu Sun. <span class="pub-venue">IJCAI-22</span>, 2852-2858. [<a href="https://www.ijcai.org/proceedings/2022/0395.pdf">pdf</a>] [<a href="https://arXiv.org/abs/2012.07437">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Knowledge Inheritance for Pre-trained Language Models</div>
  <div class="small">Yujia Qin, Yankai Lin, Jing Yi, Jiajie Zhang, Xu Han, Zhengyan Zhang, Yusheng Su, Zhiyuan Liu, <strong>Peng Li</strong>, Maosong Sun, Jie Zhou. <span class="pub-venue">NAACL 2022</span>, 3921-3937. [<a href="https://aclanthology.org/2022.naacl-main.288.pdf">pdf</a>] [<a href="https://arXiv.org/abs/2105.13880">arXiv</a>] [<a href="https://github.com/thunlp/Knowledge-Inheritance">code</a>]</div>
</div><div class="item">
  <div class="pub-title">On Transferability of Prompt Tuning for Natural Language Processing</div>
  <div class="small">Yusheng Su, Xiaozhi Wang, Yujia Qin, Chi-Min Chan, Yankai Lin, Huadong Wang, Kaiyue Wen, Zhiyuan Liu, <strong>Peng Li</strong>, Juanzi Li, Lei Hou, Maosong Sun, Jie Zhou. <span class="pub-venue">NAACL 2022</span>, 3949-3969. [<a href="https://aclanthology.org/2022.naacl-main.290.pdf">pdf</a>] [<a href="https://arXiv.org/abs/2111.06719">arXiv</a>] [<a href="https://github.com/thunlp/Prompt-Transferability">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Fully Hyperbolic Neural Networks</div>
  <div class="small">Weize Chen, Xu Han, Yankai Lin, Hexu Zhao, Zhiyuan Liu, <strong>Peng Li</strong>, Maosong Sun, Jie Zhou. <span class="pub-venue">ACL 2022</span>, 5672-5686. [<a href="https://aclanthology.org/2022.acl-long.389.pdf">pdf</a>] [<a href="https://arXiv.org/abs/2105.14686">arXiv</a>] [<a href="https://github.com/chenweize1998/fully-hyperbolic-nn">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Unsupervised Dependency Graph Network</div>
  <div class="small">Yikang Shen, Shawn Tan, Alessandro Sordoni, <strong>Peng Li</strong>, Jie Zhou, Aaron Courville. <span class="pub-venue">ACL 2022</span>, 4767-4784. [<a href="https://aclanthology.org/2022.acl-long.327.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Packed Levitated Marker for Entity and Relation Extraction</div>
  <div class="small">Deming Ye, Yankai Lin, <strong>Peng Li</strong>, Maosong Sun. <span class="pub-venue">ACL 2022</span>, 4904-4917. [<a href="https://aclanthology.org/2022.acl-long.337.pdf">pdf</a>] [<a href="https://arXiv.org/abs/2109.06067">arXiv</a>] [<a href="https://github.com/thunlp/PL-Marker">code</a>]</div>
</div><div class="item">
  <div class="pub-title">CTRLEval: An Unsupervised Reference-Free Metric for Evaluating Controlled Text Generation</div>
  <div class="small">Pei Ke, Hao Zhou, Yankai Lin, <strong>Peng Li</strong>, Jie Zhou, Xiaoyan Zhu, Minlie Huang. <span class="pub-venue">ACL 2022</span>, 2306-2319. [<a href="https://aclanthology.org/2022.acl-long.164.pdf">pdf</a>] [<a href="https://arXiv.org/abs/2204.00862">arXiv</a>] [<a href="https://github.com/thu-coai/CTRLEval">code</a>]</div>
</div><div class="item">
  <div class="pub-title">A Simple but Effective Pluggable Entity Lookup Table for Pre-trained Language Models</div>
  <div class="small">Deming Ye, Yankai Lin, <strong>Peng Li</strong>, Maosong Sun, Zhiyuan Liu. <span class="pub-venue">ACL 2022</span>, 523-529. [<a href="https://aclanthology.org/2022.acl-short.57.pdf">pdf</a>] [<a href="https://arXiv.org/abs/2202.13392">arXiv</a>] [<a href="https://github.com/thunlp/PELT">code</a>]</div>
</div><div class="item">
  <div class="pub-title">ELLE: Efficient Lifelong Pre-training for Emerging Data</div>
  <div class="small">Yujia Qin, Jiajie Zhang, Yankai Lin, Zhiyuan Liu, <strong>Peng Li</strong>, Maosong Sun, Jie Zhou. <span class="pub-venue">Findings of ACL 2022</span>, 2789-2810. [<a href="https://aclanthology.org/2022.findings-acl.220.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2203.06311">arXiv</a>] [<a href="https://github.com/thunlp/ELLE">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Do Pre-trained Models Benefit Knowledge Graph Completion? A Reliable Evaluation and a Reasonable Approach</div>
  <div class="small">Xin Lv, Yankai Lin, Yixin Cao, Lei Hou, Juanzi Li, Zhiyuan Liu, <strong>Peng Li</strong>, Jie Zhou. <span class="pub-venue">Findings of ACL 2022</span>, 3570-3581. [<a href="https://aclanthology.org/2022.findings-acl.282.pdf">pdf</a>] [<a href="https://github.com/THU-KEG/PKGC">code</a>]</div>
</div><div class="item">
  <div class="pub-title">MoEﬁcation: Transformer Feed-forward Layers are Mixtures of Experts</div>
  <div class="small">Zhengyan Zhang, Yankai Lin, Zhiyuan Liu, <strong>Peng Li</strong>, Maosong Sun, Jie Zhou. <span class="pub-venue">Findings of ACL 2022</span>, 877-890. [<a href="https://aclanthology.org/2022.findings-acl.71.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2110.01786">arXiv</a>] [<a href="https://github.com/thunlp/MoEfication">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Manual-Guided Dialogue for Flexible Conversational Agents</div>
  <div class="small">Ryuichi Takanobu, Hao Zhou, Yankai Lin, <strong>Peng Li</strong>, Jie Zhou, Minlie Huang. <span class="pub-venue">Preprint</span>. [<a href="https://arxiv.org/abs/2208.07597">arXiv</a>]</div>
</div>
    </div>
  </div>
</details>
<details class="pub" >
  <summary>2021</summary>
  <div class="two-col">
    <div class="list">
      <div class="item">
  <div class="pub-title">Topology-Imbalance Learning for Semi-Supervised Node Classification</div>
  <div class="small">Deli Chen, Yankai Lin, Guangxiang Zhao, Xuancheng Ren, <strong>Peng Li</strong>, Jie Zhou, Xu Sun. <span class="pub-venue">NeurIPS 2021</span>. [<a href="https://papers.nips.cc/paper/2021/file/fa7cdfad1a5aaf8370ebeda47a1ff1c3-Paper.pdf">pdf</a>] [<a href="https://github.com/victorchen96/ReNode">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Dynamic Knowledge Distillation for Pre-trained Language Models</div>
  <div class="small">Lei Li, Yankai Lin, Shuhuai Ren, <strong>Peng Li</strong>, Jie Zhou, Xu Sun. <span class="pub-venue">EMNLP 2021</span>, 379-389. [<a href="https://aclanthology.org/2021.emnlp-main.31.pdf">pdf</a>] [<a href="https://github.com/lancopku/DynamicKD">code</a>]</div>
</div><div class="item">
  <div class="pub-title">RAP: Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models</div>
  <div class="small">Wenkai Yang, Yankai Lin, <strong>Peng Li</strong>, Jie Zhou, Xu Sun. <span class="pub-venue">EMNLP 2021</span>, 8365-8381. [<a href="https://aclanthology.org/2021.emnlp-main.659.pdf">pdf</a>] [<a href="https://arxiv.org/abs/2110.07831">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">CodRED: A Cross-Document Relation Extraction Dataset for Acquiring Knowledge in the Wild</div>
  <div class="small">Yuan Yao, Jiaju Du, Yankai Lin, <strong>Peng Li</strong>, Zhiyuan Liu, Jie Zhou, Maosong Sun. <span class="pub-venue">EMNLP 2021</span>, 4452-4472. [<a href="https://aclanthology.org/2021.emnlp-main.366.pdf">pdf</a>] [<a href="https://github.com/thunlp/CodRED">code &amp; data</a>] [<a href="https://codalab.lisn.upsaclay.fr/competitions/3770">Leaderboard</a>]</div>
</div><div class="item">
  <div class="pub-title">CascadeBERT: Accelerating Inference of Pre-trained Language Models via Calibrated Complete Models Cascade</div>
  <div class="small">Lei Li, Yankai Lin, Deli Chen, Shuhuai Ren, <strong>Peng Li</strong>, Jie Zhou, Xu Sun. <span class="pub-venue">Findings of EMNLP 2021</span>, 475-486. [<a href="https://aclanthology.org/2021.findings-emnlp.43.pdf">pdf</a>] [<a href="https://github.com/lancopku/CascadeBERT">code</a>]</div>
</div><div class="item">
  <div class="pub-title">MOOCCubeX: A Large Knowledge-centered Repository for Adaptive Learning in MOOCs</div>
  <div class="small">Jifan Yu, Yuquan Wang, Qingyang Zhong, Gan Luo, Yiming Mao, Kai Sun, Wenzheng Feng, Wei Xu, Shulin Cao, Kaisheng Zeng, Zijun Yao, Lei Hou, Yankai Lin, <strong>Peng Li</strong>, Jie Zhou, Bin Xu, Juanzi Li, Jie Tang, Maosong Sun. <span class="pub-venue">CIKM 2021</span>, 4643-4652. [<a href="https://dl.acm.org/doi/pdf/10.1145/3459637.3482010">pdf</a>] [<a href="https://github.com/THU-KEG/MOOCCubeX">code</a>]</div>
</div><div class="item">
  <div class="pub-title">CokeBERT: Contextual Knowledge Selection and Embedding towards Enhanced Pre-Trained Language Models</div>
  <div class="small">Yusheng Su, Xu Han, Zhengyan Zhang, <strong>Peng Li</strong>, Zhiyuan Liu, Yankai Lin, Jie Zhou, Maosong Sun. <span class="pub-venue">AI Open</span>, (2):127-134. [<a href="https://doi.org/10.1016/j.aiopen.2021.06.004">pdf</a>] [<a href="https://github.com/thunlp/CokeBERT">code</a>]</div>
</div><div class="item">
  <div class="pub-title">ERICA: Improving Entity and Relation Understanding for Pre-trained Language Models via Contrastive Learning</div>
  <div class="small">Yujia Qin, Yankai Lin, Ryuichi Takanobu, Zhiyuan Liu, <strong>Peng Li</strong>, Heng Ji, Minlie Huang, Maosong Sun, Jie Zhou. <span class="pub-venue">ACL-IJCNLP 2021</span>, 3350-3363. [<a href="https://aclanthology.org/2021.acl-long.260.pdf">pdf</a>] [<a href="https://github.com/thunlp/ERICA">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Rethinking Stealthiness of Backdoor Attack against NLP Models</div>
  <div class="small">Wenkai Yang, Yankai Lin, <strong>Peng Li</strong>, Jie Zhou, Xu Sun. <span class="pub-venue">ACL-IJCNLP 2021</span>, 5543-5557. [<a href="https://aclanthology.org/2021.acl-long.431.pdf">pdf</a>] [<a href="https://github.com/lancopku/SOS">code</a>]</div>
</div><div class="item">
  <div class="pub-title">CLEVE: Contrastive Pre-training for Event Extraction</div>
  <div class="small">Ziqi Wang, Xiaozhi Wang, Xu Han, Yankai Lin, Lei Hou, Zhiyuan Liu, <strong>Peng Li</strong>, Juanzi Li, Jie Zhou. <span class="pub-venue">ACL-IJCNLP 2021</span>, 6283-6297. [<a href="https://aclanthology.org/2021.acl-long.491.pdf">pdf</a>] [<a href="https://github.com/THU-KEG/CLEVE">code</a>]</div>
</div><div class="item">
  <div class="pub-title">GoG: Relation-aware Graph-over-Graph Network for Visual Dialog</div>
  <div class="small">Feilong Chen, Xiuyi Chen, Fandong Meng, <strong>Peng Li</strong>, Jie Zhou. <span class="pub-venue">Findings of ACL-IJCNLP 2021</span>, 230-243. [<a href="https://aclanthology.org/2021.findings-acl.20.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Multimodal Incremental Transformer with Visual Grounding for Visual Dialogue Generation</div>
  <div class="small">Feilong Chen, Fandong Meng, Xiuyi Chen, <strong>Peng Li</strong>, Jie Zhou. <span class="pub-venue">Findings of ACL-IJCNLP 2021</span>, 436-446. [<a href="https://aclanthology.org/2021.findings-acl.38.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Unsupervised Knowledge Selection for Dialogue Generation</div>
  <div class="small">Xiuyi Chen, Feilong Chen, Fandong Meng, <strong>Peng Li</strong>, Jie Zhou. <span class="pub-venue">Findings of ACL-IJCNLP 2021</span>, 1230-1244. [<a href="https://aclanthology.org/2021.findings-acl.105.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Manual Evaluation Matters: Reviewing Test Protocols of Distantly Supervised Relation Extraction</div>
  <div class="small">Tianyu Gao, Xu Han, Yuzhuo Bai, Keyue Qiu, Zhiyu Xie, Yankai Lin, Zhiyuan Liu, <strong>Peng Li</strong>, Maosong Sun, Jie Zhou. <span class="pub-venue">Findings of ACL-IJCNLP 2021</span>, 1306-1318. [<a href="https://aclanthology.org/2021.findings-acl.112.pdf">pdf</a>] [<a href="https://github.com/thunlp/OpenNRE">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Aspect-Level Sentiment-Controllable Review Generation with Mutual Learning Framework</div>
  <div class="small">Huimin Chen, Yankai Lin, Fanchao Qi, Jinyi Hu, <strong>Peng Li</strong>, Jie Zhou, Maosong Sun. <span class="pub-venue">AAAI 2021</span>, 12639-12647. [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17497/17304">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Guiding Non-Autoregressive Neural Machine Translation Decoding with Reordering Information</div>
  <div class="small">Qiu Ran*, Yankai Lin*, <strong>Peng Li</strong>*, Jie Zhou. <span class="pub-venue">AAAI 2021</span>, 13727-13735. [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/17618/17425">pdf</a>] [<a href="https://github.com/ranqiu92/ReorderNAT">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Context Tracking Network: Graph-based Context Modeling for Implicit Discourse Relation Recognition</div>
  <div class="small">Yingxue Zhang, Fandong Meng, <strong>Peng Li</strong>, Ping Jian, Jie Zhou. <span class="pub-venue">NAACL 2021</span>, 1592–1599. [<a href="https://www.aclweb.org/anthology/2021.naacl-main.126.pdf">pdf</a>] [<a href="https://github.com/nangying1112/CTNet">code</a>]</div>
</div><div class="item">
  <div class="pub-title">CSS-LM: A Contrastive Framework for Semi-supervised Fine-tuning of Pre-trained Language Models</div>
  <div class="small">Yusheng Su, Xu Han, Yankai Lin, Zhengyan Zhang, Zhiyuan Liu, <strong>Peng Li</strong>, Jie Zhou, Maosong Sun. <span class="pub-venue">IEEE/ACM Transactions on Audio, Speech and Language Processing (TASLP)</span>, (29):2930-2941. [<a href="https://ieeexplore.ieee.org/document/9535242?source=authoralert">pdf</a>] [<a href="https://github.com/thunlp/CSS-LM">code</a>]</div>
</div><div class="item">
  <div class="pub-title">WeChat Neural Machine Translation Systems for WMT21</div>
  <div class="small">Xianfeng Zeng, Yijin Liu, Ernan Li, Qiu Ran, Fandong Meng, <strong>Peng Li</strong>, Jinan Xu, Jie Zhou. <span class="pub-venue">WMT21</span>, 243–254. [<a href="https://aclanthology.org/2021.wmt-1.23.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">MS-Ranker: Accumulating Evidence from Potentially Correct Candidates via Reinforcement Learning for Answer Selection</div>
  <div class="small">Yingxue Zhang, Fandong Meng, <strong>Peng Li</strong>, Ping Jian, Jie Zhou. <span class="pub-venue">Neurocomputing</span>, (449):270-279. [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221004690">pdf</a>]</div>
</div>
    </div>
  </div>
</details>
<details class="pub" >
  <summary>2020</summary>
  <div class="two-col">
    <div class="list">
      <div class="item">
  <div class="pub-title">Bridging the Gap between Prior and Posterior Knowledge Selection for Knowledge-Grounded Dialogue Generation</div>
  <div class="small">Xiuyi Chen, Fandong Meng, <strong>Peng Li</strong>, Feilong Chen, Shuang Xu, Bo Xu, Jie Zhou. <span class="pub-venue">EMNLP 2020</span>, 3426–3437. [<a href="https://www.aclweb.org/anthology/2020.emnlp-main.275.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Learning from Context or Names? An Empirical Study on Neural Relation Extraction</div>
  <div class="small">Hao Peng, Tianyu Gao, Xu Han, Yankai Lin, <strong>Peng Li</strong>, Zhiyuan Liu, Maosong Sun, Jie Zhou. <span class="pub-venue">EMNLP 2020</span>, 3661–3672. [<a href="https://www.aclweb.org/anthology/2020.emnlp-main.298.pdf">pdf</a>] [<a href="https://github.com/thunlp/RE-Context-or-Names">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Coreferential Reasoning Learning for Language Representation</div>
  <div class="small">Deming Ye, Yankai Lin, Jiaju Du, Zhenghao Liu, <strong>Peng Li</strong>, Maosong Sun, Zhiyuan Liu. <span class="pub-venue">EMNLP 2020</span>, 7170–7186. [<a href="https://www.aclweb.org/anthology/2020.emnlp-main.582.pdf">pdf</a>] [<a href="https://github.com/thunlp/CorefBERT">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Disentangle-based Continual Graph Representation Learning</div>
  <div class="small">Xiaoyu Kou, Yankai Lin, Shaobo Liu, <strong>Peng Li</strong>, Jie Zhou, Yan Zhang. <span class="pub-venue">EMNLP 2020</span>, 2961-2972. [<a href="https://www.aclweb.org/anthology/2020.emnlp-main.237.pdf">pdf</a>] [<a href="https://github.com/KXY-PUBLIC/DiCGRL">code</a>]</div>
</div><div class="item">
  <div class="pub-title">MAVEN: A Massive General Domain Event Detection Dataset</div>
  <div class="small">Xiaozhi Wang, Ziqi Wang, Xu Han, Wangyi Jiang, Rong Han, Zhiyuan Liu, Juanzi Li, <strong>Peng Li</strong>, Yankai Lin, Jie Zhou. <span class="pub-venue">EMNLP 2020</span>, 1652–1671. [<a href="https://www.aclweb.org/anthology/2020.emnlp-main.129.pdf">pdf</a>] [<a href="https://github.com/THU-KEG/MAVEN-dataset">code</a>]</div>
</div><div class="item">
  <div class="pub-title">WeChat Neural Machine Translation Systems for WMT20</div>
  <div class="small">Fandong Meng, Jianhao Yan, Yijin Liu, Yuan Gao, Xianfeng Zeng, Qinsong Zeng, <strong>Peng Li</strong>, Ming Chen, Jie Zhou, Sifan Liu, Hao Zhou. <span class="pub-venue">WMT20</span>, 239–247. [<a href="https://aclanthology.org/2020.wmt-1.24.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Learning to Recover from Multi-Modality Errors for Non-Autoregressive Neural Machine Translation</div>
  <div class="small">Qiu Ran*, Yankai Lin*, <strong>Peng Li</strong>*, Jie Zhou. <span class="pub-venue">ACL 2020</span>, 3059–3069. [<a href="https://www.aclweb.org/anthology/2020.acl-main.277.pdf">pdf</a>] [<a href="https://github.com/ranqiu92/RecoverSAT">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Continual Relation Learning via Episodic Memory Activation and Reconsolidation</div>
  <div class="small">Xu Han, Yi Dai, Tianyu Gao, Yankai Lin, Zhiyuan Liu, <strong>Peng Li</strong>, Maosong Sun, Jie Zhou. <span class="pub-venue">ACL 2020</span>, 6429–6440. [<a href="https://www.aclweb.org/anthology/2020.acl-main.573.pdf">pdf</a>] [<a href="https://github.com/thunlp/ContinualRE">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Measuring and Relieving the Over-smoothing Problem for Graph Neural Networks from the Topological View</div>
  <div class="small">Deli Chen, Yankai Lin, Wei Li, <strong>Peng Li</strong>, Jie Zhou, Xu Sun. <span class="pub-venue">AAAI 2020</span>, 3438-3445. [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/5747/5603">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">DMRM: A Dual-channel Multi-hop Reasoning Model for Visual Dialog</div>
  <div class="small">Feilong Chen, Fandong Meng, Jiaming Xu, <strong>Peng Li</strong>, Bo Xu, Jie Zhou. <span class="pub-venue">AAAI 2020</span>, 7504-7511. [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/6248/6104">pdf</a>] [<a href="https://github.com/phellonchen/DMRM">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Neural Gibbs Sampling for Joint Event Argument Extraction</div>
  <div class="small">Xiaozhi Wang, Shengyu Jia, Xu Han, Zhiyuan Liu, Juanzi Li, <strong>Peng Li</strong>, Jie Zhou. <span class="pub-venue">AACL 2020</span>, 169-180. [<a href="https://www.aclweb.org/anthology/2020.aacl-main.21.pdf">pdf</a>] [<a href="https://github.com/THU-KEG/NGS">code</a>]</div>
</div><div class="item">
  <div class="pub-title">More Data, More Relations, More Context and More Openness: A Review and Outlook for Relation Extraction</div>
  <div class="small">Xu Han, Tianyu Gao, Yankai Lin, Hao Peng, Yaoliang Yang, Chaojun Xiao, Zhiyuan Liu, <strong>Peng Li</strong>, Jie Zhou, Maosong Sun. <span class="pub-venue">AACL 2020</span>, 745-758. [<a href="https://www.aclweb.org/anthology/2020.aacl-main.75.pdf">pdf</a>]</div>
</div>
    </div>
  </div>
</details>
<details class="pub" >
  <summary>2019</summary>
  <div class="two-col">
    <div class="list">
      <div class="item">
  <div class="pub-title">NumNet: Machine Reading Comprehension with Numerical Reasoning</div>
  <div class="small">Qiu Ran, Yankai Lin, <strong>Peng Li</strong>, Jie Zhou, Zhiyuan Liu. <span class="pub-venue">EMNLP 2019</span>, 2474-2484. [<a href="https://www.aclweb.org/anthology/D19-1251.pdf">pdf</a>] [<a href="https://github.com/ranqiu92/NumNet">code</a>]</div>
</div><div class="item">
  <div class="pub-title">HMEAE: Hierarchical Modular Event Argument Extraction</div>
  <div class="small">Xiaozhi Wang, Ziqi Wang, Xu Han, Zhiyuan Liu, Juanzi Li, <strong>Peng Li</strong>, Maosong Sun, Jie Zhou, Xiang Ren. <span class="pub-venue">EMNLP 2019</span>, 5777–5783. [<a href="https://www.aclweb.org/anthology/D19-1584.pdf">pdf</a>] [<a href="https://github.com/thunlp/HMEAE">code</a>]</div>
</div><div class="item">
  <div class="pub-title">FewRel 2.0: Towards More Challenging Few-Shot Relation Classification</div>
  <div class="small">Tianyu Gao, Xu Han, Hao Zhu, Zhiyuan Liu, <strong>Peng Li</strong>, Maosong Sun, Jie Zhou. <span class="pub-venue">EMNLP 2019</span>, 6250–6255. [<a href="https://www.aclweb.org/anthology/D19-1649.pdf">pdf</a>] [<a href="https://github.com/thunlp/FewRel">code</a>] [<a href="https://thunlp.github.io/fewrel.html">benchmark</a>]</div>
</div><div class="item">
  <div class="pub-title">DocRED: A Large-Scale Document-Level Relation Extraction Dataset</div>
  <div class="small">Yuan Yao, Deming Ye, <strong>Peng Li</strong>, Xu Han, Yankai Lin, Zhenghao Liu, Zhiyuan Liu, Lixin Huang, Jie Zhou, Maosong Sun. <span class="pub-venue">ACL 2019</span>, 764-777. [<a href="https://aclanthology.org/P19-1074.pdf">pdf</a>] [<a href="https://github.com/thunlp/DocRED">code &amp; data</a>] [<a href="https://competitions.codalab.org/competitions/20147">Leaderboard</a>]</div>
</div><div class="item">
  <div class="pub-title">Towards Fine-grained Text Sentiment Transfer</div>
  <div class="small">Fuli Luo, <strong>Peng Li</strong>, Pengcheng Yang, Jie Zhou, Yutong Tan, Baobao Chang, Zhifang Sui, Xu Sun. <span class="pub-venue">ACL 2019</span>, 2013-2022. [<a href="https://aclanthology.org/P19-1194.pdf">pdf</a>] [<a href="https://github.com/luofuli/Fine-grained-Sentiment-Transfer">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Key Fact as Pivot: A Two-Stage Model for Low Resource Table-to-Text Generation</div>
  <div class="small">Shuming Ma, Pengcheng Yang, Tianyu Liu, <strong>Peng Li</strong>, Jie Zhou, Xu Sun. <span class="pub-venue">ACL 2019</span>, 2047-2057. [<a href="https://aclanthology.org/P19-1197.pdf">pdf</a>] [<a href="https://github.com/lancopku/Pivot">code</a>]</div>
</div><div class="item">
  <div class="pub-title">A Dual Reinforcement Learning Framework for Unsupervised Text Style Transfer</div>
  <div class="small">Fuli Luo, <strong>Peng Li</strong>, Jie Zhou, Pengcheng Yang, Baobao Chang, Xu Sun, Zhifang Sui. <span class="pub-venue">IJCAI 2019</span>, 5116-5122. [<a href="https://www.ijcai.org/proceedings/2019/0711.pdf">pdf</a>] [<a href="https://github.com/luofuli/DualRL">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Adversarial Training for Weakly Supervised Event Detection</div>
  <div class="small">Xiaozhi Wang, Xu Han, Zhiyuan Liu, Maosong Sun, <strong>Peng Li</strong>. <span class="pub-venue">NAACL 2019</span>, 998-1008. [<a href="https://aclanthology.org/N19-1105.pdf">pdf</a>] [<a href="https://github.com/thunlp/Adv-ED">code</a>]</div>
</div><div class="item">
  <div class="pub-title">HighwayGraph: Modelling Long-distance Node Relations for Improving General Graph Neural Networks</div>
  <div class="small">Deli Chen, Xiaoqian Liu, Yankai Lin, <strong>Peng Li</strong>, Jie Zhou, Qi Su, Xu Sun. <span class="pub-venue">Preprint</span>. [<a href="https://arXiv.org/abs/1911.03904">arXiv</a>]</div>
</div><div class="item">
  <div class="pub-title">Option Comparison Network for Multiple-choice Reading Comprehension</div>
  <div class="small">Qiu Ran, <strong>Peng Li</strong>, Weiwei Hu, Jie Zhou. <span class="pub-venue">Preprint</span>. [<a href="https://arXiv.org/pdf/1903.03033.pdf">arXiv</a>] [<a href="https://github.com/ranqiu92/OCN">code</a>]</div>
</div>
    </div>
  </div>
</details>
<details class="pub" >
  <summary>2018 and earlier</summary>
  <div class="two-col">
    <div class="list">
      <div class="item">
  <div class="pub-title">Hierarchical Relation Extraction with Coarse-to-Fine Grained Attention</div>
  <div class="small">Xu Han, Pengfei Yu, Zhiyuan Liu, Maosong Sun, <strong>Peng Li</strong>. <span class="pub-venue">EMNLP 2018</span>, 2236-2245. [<a href="https://aclanthology.org/D18-1247.pdf">pdf</a>] [<a href="https://github.com/thunlp/HNRE">code</a>]</div>
</div><div class="item">
  <div class="pub-title">Dataset and Neural Recurrent Sequence Labeling Model for Open-Domain Factoid Question Answering</div>
  <div class="small"><strong>Peng Li</strong>, Wei Li, Zhengyan He, Xuguang Wang, Ying Cao, Jie Zhou, Wei Xu. <span class="pub-venue">Preprint</span>. [<a href="https://arXiv.org/abs/1607.06275">arXiv</a>] [<a href="https://github.com/pengli09/models/archive/neural-qa-verified.zip">code (in the directory "neural_qa", veryfied on Ubuntu 16.04 with <a href="https://pypi.python.org/pypi/paddlepaddle/0.10.5">PaddlePaddle 0.10.5</a>)</a>]</div>
</div><div class="item">
  <div class="pub-title">Deep Recurrent Models with Fast-Forward Connections for Neural Machine Translation</div>
  <div class="small">Jie Zhou, Ying Cao, Xuguang Wang, <strong>Peng Li</strong>, Wei Xu. <span class="pub-venue">Transactions of the Association for Computational Linguistics (TACL)</span>, (4):371-383. [<a href="https://aclanthology.org/Q16-1027.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">A Neural Reordering Model for Phrase-based Translation</div>
  <div class="small"><strong>Peng Li</strong>, Yang Liu, Maosong Sun, Tatsuya Izuha, Dakun Zhang. <span class="pub-venue">COLING 2014</span>, 1897-1907. [<a href="https://aclanthology.org/C14-1179.pdf">pdf</a>] [<a href="talks/coling-2014.pdf">slides</a>]</div>
</div><div class="item">
  <div class="pub-title">Neural Reordering Model for Hierarchical Phrase-based Translations</div>
  <div class="small"><strong>Peng Li</strong>, Yang Liu, Maosong Sun. <span class="pub-venue">J Tsinghua Univ (Sci & Technol)</span>, (54):1529-1533. </div>
</div><div class="item">
  <div class="pub-title">Recursive Autoencoders for ITG-based Translation</div>
  <div class="small"><strong>Peng Li</strong>, Yang Liu, Maosong Sun. <span class="pub-venue">EMNLP 2013</span>, 567-577. [<a href="https://aclanthology.org/D13-1054.pdf">pdf</a>] [<a href="talks/pengli-tsinghua-rae-itg-mt.pdf">Talk at MSRA Ph.D Forum</a>]</div>
</div><div class="item">
  <div class="pub-title">An Extended GHKM Algorithm for Inducing Lambda-SCFG</div>
  <div class="small"><strong>Peng Li</strong>, Yang Liu, Maosong Sun. <span class="pub-venue">AAAI-13</span>, 605-611. [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/8567/8426">pdf</a>] [<a href="publications/aaai-2013-slides.pdf">slides</a>]</div>
</div><div class="item">
  <div class="pub-title">A Beam Search Algorithm for ITG Word Alignment</div>
  <div class="small"><strong>Peng Li</strong>, Yang Liu, Maosong Sun. <span class="pub-venue">COLING 2012: Posters</span>, 673-682. [<a href="https://aclanthology.org/C12-2066.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Fast-Champollion: A Fast and Robust Sentence Alignment Algorithm</div>
  <div class="small"><strong>Peng Li</strong>, Maosong Sun, Ping Xue. <span class="pub-venue">COLING 2010: Posters</span>, 710-718. [<a href="https://aclanthology.org/C10-2081.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Content-based and Graph-based Tag Suggestion</div>
  <div class="small">Xiance Si, Zhiyuan Liu, <strong>Peng Li</strong>, Qixia Jiang, Maosong Sun. <span class="pub-venue">ECML/PKDD 2009 Discovery Challenge Workshop</span>, 243-260. [<a href="publications/dc2009.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Clustering to Find Exemplar Terms for Keyphrase Extraction</div>
  <div class="small">Zhiyuan Liu, <strong>Peng Li</strong>, Yabin Zheng, Maosong Sun. <span class="pub-venue">EMNLP 2009</span>, 257-266. [<a href="https://aclanthology.org/D09-1027.pdf">pdf</a>]</div>
</div><div class="item">
  <div class="pub-title">Community Detection by Affinity Propagation</div>
  <div class="small">Zhiyuan Liu, <strong>Peng Li</strong>, Yabin Zheng, Maosong Sun. <span class="pub-venue">Technical Report</span>. [<a href="techreports/TR001_thunlp_community_detection.pdf">pdf</a>]</div>
</div>
    </div>
  </div>
</details>
    </section>

    <section class="section" id="services">
      <h2>Professional Services</h2>
      <div class="grid grid-cols-2">
        <ul class="list">
          <li><strong>Senior Area Chair</strong>: AACL (2022)</li>
          <li><strong>Area Chair</strong>:<!--ICLR (2026), --> ACL (2024–2025), EMNLP (2024), NAACL (2024–2025), EACL (2024), COLING (2022)<!--, AACL (2025)--></li>
          <li><strong>Action Editor</strong>: ACL Rolling Review (ARR)</li>
          <li><strong>PC Chair</strong>: YWCL (2010)</li>
          <li><strong>Tutorial Chair</strong>: CCL (2023), CCMT (2023, 2025)</li>
          <li><strong>Demonstration Chair</strong>: CCL (2024)</li>
          <li><strong>Frontier Forum Chair</strong>: CCMT (2024)</li>
          <li><strong>Publicity Chair</strong>: CCL (2025)</li>
        </ul>
        <ul class="list">
          <li><strong>Reviewer / PC Member</strong>: NeurIPS (2022–2025), ICML (2022–2025), ICLR (2024–2025), ACL (2014, 2021–2023), EMNLP (2014, 2021–2023), NAACL (2018), CVPR (2023–2025<!--2026-->), ICCV (2023, 2025), ECCV (2024), AAAI (2022–2025), IJCAI (2022–2024), COLING (2020, 2024, 2025), BMVC (2024), COLM (2024–2025), ICRA (2025-2026), ACM TIST (2015), TACL (Standing Reviewer), Acta Automatica Sinica</li>
        </ul>
      </div>
    </section>

    <section class="section" id="education">
      <h2>Education</h2>
      <ul class="list">
        <li>Ph.D., Computer Science and Technology, Tsinghua University, Beijing, China (Aug 2009 – Jan 2015)</li>
        <li>B.S., Computer Science and Technology, Tsinghua University, Beijing, China (Aug 2005 – Jul 2009)</li>
      </ul>
    </section>

    <footer class="section">
      <div class="small">Last updated: <span id="lastUpdated">Oct 05, 2025</span></div>
    </footer>
  </div>

  <script>
    // Obfuscated email to reduce scraping
    const emailUser = 'pengli09';
    const emailDomain = 'gmail.com';
    const emailLink = document.getElementById('email-link');
    emailLink.href = `mailto:${emailUser}@${emailDomain}`;
    emailLink.title = `${emailUser} at ${emailDomain}`;
  </script>
</body>
</html>